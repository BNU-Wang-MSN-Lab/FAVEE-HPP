{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83aba9aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:54.205823Z",
     "start_time": "2022-12-15T13:37:52.984816Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import squareform\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f83fce3",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a706ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:54.221833Z",
     "start_time": "2022-12-15T13:37:54.207825Z"
    }
   },
   "outputs": [],
   "source": [
    "# Meadows ID and corresponding fMRI ID\n",
    "meadows_soc_id_key = pd.read_csv('../input_data/meadows_data/participants.csv',index_col=0)\n",
    "# Create a list of paths for each subject's data\n",
    "ma_subj_data_paths = glob.glob('../input_data/meadows_data/meadows_subject_data/*.mat')\n",
    "ca_subj_data_paths = glob.glob('../input_data/meadows_data/meadows_subject_data/*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6815bad0",
   "metadata": {},
   "source": [
    "Notably, there were two versions of relationships labels. One version left out \"Between\" in some relationships and the order was different from another one. Without unify one type of labels and the order, the corresponding different matrix added would make mistakes.\n",
    "The two types of versions were shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb91810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:54.237837Z",
     "start_time": "2022-12-15T13:37:54.222832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Wife - Husband', 'Nurse - Patient', 'Officer - Soldier', 'Neighbors',\n",
       "       'Athletic trainer - Trainee', 'Police officer - Offender',\n",
       "       'Principal - Teacher', 'Doctor - Nurse', 'Victim - Criminal',\n",
       "       'Coach - Athlete',\n",
       "       ...\n",
       "       'Sorority sisters', 'Classmates', 'Club-member - Club-president',\n",
       "       'Political opponents', 'Friends-with-benefits',\n",
       "       'Foster-parent - Foster-child', 'Business rivals',\n",
       "       'Manager - Assistant', 'Victim - Witness', 'Business partners'],\n",
       "      dtype='object', length=159)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 10 #depend on specific file path\n",
    "mat = loadmat(ma_subj_data_paths[30]) #the index was chosen randomly but prefer to choose the first few\n",
    "    \n",
    "# Extract each social relationship stimuli and clean them up\n",
    "relationships=[]\n",
    "for i in mat['stimuli']:\n",
    "    temp_str = i.replace('  ','')\n",
    "    temp_str = temp_str.strip()\n",
    "    relationships.append(temp_str)\n",
    "\n",
    "\n",
    "soc_id = meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == \\\n",
    "                            ma_subj_data_paths[30].split('_')[num]].index[0]\n",
    "soc_id = soc_id.replace('soc','sub')\n",
    "# Turn the 1-D matlab array into a 2-D distance matrix\n",
    "dissim_v1 = pd.DataFrame(squareform(mat['rdmutv'][0]), columns=relationships, index=relationships)\n",
    "dissim_v1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458b7011",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:54.253387Z",
     "start_time": "2022-12-15T13:37:54.240384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Parent - Child', 'Parent - Teenager', 'Wife - Husband',\n",
       "       'Fiance - Fiancee', 'Siblings', 'Divorced spouses',\n",
       "       'A person - Their in-laws', 'Cousins', 'Employer - Employee',\n",
       "       'Interviewer - Job applicant',\n",
       "       ...\n",
       "       'Monarch - Minister', 'Confidants', 'Person - Significant other',\n",
       "       'Companions', 'Playmates', 'Competitors in sports', 'Person - Crush',\n",
       "       'Cohabitants', 'Long-distance-lovers', 'Brothers-in-arms'],\n",
       "      dtype='object', length=159)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = loadmat(ma_subj_data_paths[56])#the index was chosen randomly but prefer to choose the last few\n",
    "    \n",
    "# Extract each social relationship stimuli and clean them up\n",
    "relationships=[]\n",
    "for i in mat['stimuli']:\n",
    "    temp_str = i.replace('  ','')\n",
    "    temp_str = temp_str.strip()\n",
    "    relationships.append(temp_str)\n",
    "\n",
    "\n",
    "soc_id = meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == ma_subj_data_paths[56].split('_')[num]].index[0]\n",
    "soc_id = soc_id.replace('soc','sub')\n",
    "# Turn the 1-D matlab array into a 2-D distance matrix\n",
    "dissim_v2 = pd.DataFrame(squareform(mat['rdmutv'][0]), columns=relationships, index=relationships)\n",
    "dissim_v2.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d783d5",
   "metadata": {},
   "source": [
    "Due to the two versions of relatioships, the codes adjusting the labels were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e022802c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:54.268425Z",
     "start_time": "2022-12-15T13:37:54.255388Z"
    }
   },
   "outputs": [],
   "source": [
    "#In categorization task, there were two different versions in labels of relationships, which were shown in '2.2 different relationship labels'.\n",
    "#This function is used to turn relationships in version 2 into version 1.\n",
    "def rel_v2_to_v1(df): \n",
    "    df = df.rename(columns = {'Diplomats': 'Between Diplomats'}, \n",
    "                  index = {'Diplomats': 'Between Diplomats'})\n",
    "    df = df.rename(columns = {'Second-cousins': 'Between Second-cousins'}, \n",
    "                   index = {'Second-cousins': 'Between Second-cousins'})\n",
    "    df = df.rename(columns = {'Co-workers': 'Between Co-workers'}, \n",
    "                   index = {'Co-workers': 'Between Co-workers'})\n",
    "    df = df.rename(columns = {'Person - Significant other': 'Person - their Significant other'}, \n",
    "                   index = {'Person - Significant other': 'Person - their Significant other'})\n",
    "    df = df.rename(columns = {'Step-siblings': 'Between Step-siblings'}, \n",
    "                   index = {'Step-siblings': 'Between Step-siblings'}) \n",
    "    df = df.rename(columns = {'Twins': 'Between Twins'}, \n",
    "                   index = {'Twins': 'Between Twins'}) \n",
    "    df = df.rename(columns = {'Frenemies': 'Between Frenemies'}, \n",
    "                   index = {'Frenemies': 'Between Frenemies'}) \n",
    "    df = df.rename(columns = {'Alumni': 'Between Alumni'}, \n",
    "                   index = {'Alumni': 'Between Alumni'}) \n",
    "    df = df.rename(columns = {'Playmates': 'Between Playmates'}, \n",
    "                   index = {'Playmates': 'Between Playmates'})      \n",
    "    df = df.rename(columns = {'Half-siblings': 'Between Half-siblings'}, \n",
    "                   index = {'Half-siblings': 'Between Half-siblings'}) \n",
    "    df = df.rename(columns = {'Peers': 'Between Peers'}, \n",
    "                   index = {'Peers': 'Between Peers'}) \n",
    "    df = df.rename(columns = {'Companions': 'Between Companions'}, \n",
    "                   index = {'Companions': 'Between Companions'}) \n",
    "    df = df.rename(columns = {'Person - Social media follower': 'Person - their Social media follower'}, \n",
    "                   index = {'Person - Social media follower': 'Person - their Social media follower'})\n",
    "    df = df.rename(columns = {'Cousins': 'Between Cousins'}, \n",
    "                   index = {'Cousins': 'Between Cousins'}) \n",
    "    df = df.rename(columns = {'Cohabitants': 'Between Cohabitants'}, \n",
    "                   index = {'Cohabitants': 'Between Cohabitants'}) \n",
    "    df = df.rename(columns = {'Confidants': 'Between Confidants'}, \n",
    "                   index = {'Confidants': 'Between Confidants'}) \n",
    "    df = df.rename(columns = {'Siblings': 'Between Siblings'}, \n",
    "                   index = {'Siblings': 'Between Siblings'}) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f3058c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:54.283748Z",
     "start_time": "2022-12-15T13:37:54.269425Z"
    }
   },
   "outputs": [],
   "source": [
    "#Match the labels in categorization task with that in dimension rating task.\n",
    "def fix_df_labels(df):\n",
    "    # Make conditions list and the columns/rows of the distance matrix lowercase\n",
    "    df.columns = [x.lower() for x in df.columns]\n",
    "    df.index = [x.lower() for x in df.index]\n",
    "\n",
    "    # Fix up the conditions lists and the columns/rows of the matrix so that they match\n",
    "    ## There were some small typos and string differences between the two\n",
    "    df.columns = df.columns.str.replace('–','and')\n",
    "    df.index = df.index.str.replace('–','and')\n",
    "    df.columns = df.columns.str.replace(' - ',' and ')\n",
    "    df.index = df.index.str.replace(' - ',' and ')\n",
    "    df.columns = df.columns.str.replace('  ',' ')\n",
    "    df.index = df.index.str.replace('  ',' ')  \n",
    "    df.columns = df.columns.str.replace('between ','')\n",
    "    df.index = df.index.str.replace('between ','')\n",
    "    \n",
    "    #unify the labels in categorization task and those in dimension rating task.\n",
    "    df.columns = df.columns.str.replace('-',' ')\n",
    "    df.index = df.index.str.replace('-',' ') \n",
    "    \n",
    "    df = df.rename(columns = {'monarch and minister': 'a monarch and their minister'}, \n",
    "                   index = {'monarch and minister': 'a monarch and their minister'})\n",
    "    df = df.rename(columns = {'person and crush': 'a person and their crush'}, \n",
    "                   index = {'person and crush': 'a person and their crush'})\n",
    "    df = df.rename(columns = {'person and deceased spouse': 'a person and their deceased spouse'}, \n",
    "                   index = {'person and deceased spouse': 'a person and their deceased spouse'})\n",
    "    df = df.rename(columns = {'person and family friends': 'a person and their family friends'}, \n",
    "                   index = {'person and family friends': 'a person and their family friends'}) \n",
    "    df = df.rename(columns = {'person and their significant other': 'a person and their significant other'}, \n",
    "                   index = {'person and their significant other': 'a person and their significant other'})\n",
    "    df = df.rename(columns = {'person and their social media follower': 'a person and their social media follower'}, \n",
    "                   index = {'person and their social media follower': 'a person and their social media follower'}) \n",
    "    df = df.rename(columns = {'uncle and neice/nephew': 'uncle and niece/nephew'}, \n",
    "                   index = {'uncle and neice/nephew': 'uncle and niece/nephew'})     \n",
    "    df = df.rename(columns = {\"man's wife and man's mistress\": 'man wife and man mistress'}, \n",
    "                   index = {\"man's wife and man's mistress\": 'man wife and man mistress'})    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3af07",
   "metadata": {},
   "source": [
    "# Multi-Arrangement Task Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc1d6f7",
   "metadata": {},
   "source": [
    "## Extract the list of participants in the second version including relative less members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0541d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:54.347723Z",
     "start_time": "2022-12-15T13:37:54.285749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159sub-762{'Peers', 'Companions', 'Confidants', 'Person - Significant other', 'Cohabitants', 'Half-siblings', 'Siblings', 'Person - Social media follower', 'Second-cousins', 'Co-workers', 'Diplomats', 'Twins', 'Playmates', 'Frenemies', 'Cousins', 'Alumni', 'Step-siblings'}\n",
      "159sub-763{'Peers', 'Companions', 'Confidants', 'Person - Significant other', 'Cohabitants', 'Half-siblings', 'Siblings', 'Person - Social media follower', 'Second-cousins', 'Co-workers', 'Diplomats', 'Twins', 'Playmates', 'Frenemies', 'Cousins', 'Alumni', 'Step-siblings'}\n",
      "159sub-765{'Peers', 'Companions', 'Confidants', 'Person - Significant other', 'Cohabitants', 'Half-siblings', 'Siblings', 'Person - Social media follower', 'Second-cousins', 'Co-workers', 'Diplomats', 'Twins', 'Playmates', 'Frenemies', 'Cousins', 'Alumni', 'Step-siblings'}\n",
      "159sub-766{'Peers', 'Companions', 'Confidants', 'Person - Significant other', 'Cohabitants', 'Half-siblings', 'Siblings', 'Person - Social media follower', 'Second-cousins', 'Co-workers', 'Diplomats', 'Twins', 'Playmates', 'Frenemies', 'Cousins', 'Alumni', 'Step-siblings'}\n",
      "159sub-502{'Peers', 'Companions', 'Confidants', 'Person - Significant other', 'Cohabitants', 'Half-siblings', 'Siblings', 'Person - Social media follower', 'Second-cousins', 'Co-workers', 'Diplomats', 'Twins', 'Playmates', 'Frenemies', 'Cousins', 'Alumni', 'Step-siblings'}\n",
      "159sub-764{'Peers', 'Companions', 'Confidants', 'Person - Significant other', 'Cohabitants', 'Half-siblings', 'Siblings', 'Person - Social media follower', 'Second-cousins', 'Co-workers', 'Diplomats', 'Twins', 'Playmates', 'Frenemies', 'Cousins', 'Alumni', 'Step-siblings'}\n",
      "159sub-767{'Peers', 'Companions', 'Confidants', 'Person - Significant other', 'Cohabitants', 'Half-siblings', 'Siblings', 'Person - Social media follower', 'Second-cousins', 'Co-workers', 'Diplomats', 'Twins', 'Playmates', 'Frenemies', 'Cousins', 'Alumni', 'Step-siblings'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sub-762', 'sub-763', 'sub-765', 'sub-766', 'sub-502', 'sub-764', 'sub-767']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_v1 = loadmat(ma_subj_data_paths[1]) # the index of zero is a null file\n",
    "relationship_ma_v1 = []\n",
    "for i in mat_v1['stimuli']:\n",
    "    temp_str = i.replace('  ','')\n",
    "    temp_str = temp_str.strip()\n",
    "    relationship_ma_v1.append(temp_str)\n",
    "\n",
    "# Loop through the data file paths\n",
    "rel_ma_v2 = []\n",
    "for p in ma_subj_data_paths:\n",
    "    mat = loadmat(p)\n",
    "    \n",
    "    # Check whether an soc ID match was found for the meadows ID.\n",
    "    if meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == p.split('_')[num]].index.empty:\n",
    "        continue\n",
    "    else:  # If match is found, this runs\n",
    "        soc_id = meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == p.split('_')[num]].index[0]\n",
    "        soc_id = soc_id.replace('soc','sub')    \n",
    "        \n",
    "    # Extract each social relationship stimuli and clean them up\n",
    "    relationships=[]\n",
    "    for i in mat['stimuli']:\n",
    "        temp_str = i.replace('  ','')\n",
    "        temp_str = temp_str.strip()\n",
    "        relationships.append(temp_str)\n",
    "    \n",
    "    if any(set(relationships)-set(relationship_ma_v1)): # If two sets of relationships are different, the results are true.\n",
    "        print(len(relationships),end='')\n",
    "        print(soc_id,end='')\n",
    "        print(set(relationships)-set(relationship_ma_v1))\n",
    "        rel_ma_v2.append(soc_id)\n",
    "rel_ma_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb0b4e",
   "metadata": {},
   "source": [
    "## Main transfer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438a08b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:56.390518Z",
     "start_time": "2022-12-15T13:37:54.349725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through the data file paths\n",
    "for p in ma_subj_data_paths:\n",
    "    mat = loadmat(p)\n",
    "    \n",
    "    # Extract each social relationship stimuli and clean them up\n",
    "    relationships=[]\n",
    "    for i in mat['stimuli']:\n",
    "        temp_str = i.replace('  ','')\n",
    "        temp_str = temp_str.strip()\n",
    "        relationships.append(temp_str)\n",
    "    \n",
    "    # Check whether an soc ID match was found for the meadows ID.\n",
    "    if meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == p.split('_')[num]].index.empty:\n",
    "        continue\n",
    "    else:  # If match is found, this runs\n",
    "        soc_id = meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == p.split('_')[num]].index[0]\n",
    "        soc_id = soc_id.replace('soc','sub')\n",
    "        # Turn the 1-D matlab array into a 2-D distance matrix\n",
    "        dissim = pd.DataFrame(squareform(mat['rdmutv'][0]), columns=relationships, index=relationships)\n",
    "\n",
    "        ### Turn relationships labels in version 2 into version 1.\n",
    "        if soc_id in rel_ma_v2:\n",
    "            dissim = rel_v2_to_v1(dissim)\n",
    "            dissim = dissim.loc[relationship_ma_v1,relationship_ma_v1]\n",
    "        ###\n",
    "        \n",
    "        #Add the labels' adjustment\n",
    "        dissim = fix_df_labels(dissim) \n",
    "        \n",
    "        dissim.to_csv('../output_data/individual/category/Subject_MA_RDMs_revised/'+soc_id+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6694b",
   "metadata": {},
   "source": [
    "# Category Arrangment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c73ca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:56.467535Z",
     "start_time": "2022-12-15T13:37:56.392518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sub-760',\n",
       " 'sub-761',\n",
       " 'sub-759',\n",
       " 'sub-762',\n",
       " 'sub-763',\n",
       " 'sub-765',\n",
       " 'sub-766',\n",
       " 'sub-502',\n",
       " 'sub-764',\n",
       " 'sub-767']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The dataframe of following subjects had no index, which resulted in a few relationships failing to be recorded.\n",
    "subj_no_list = []\n",
    "meadows_id_no_list = []\n",
    "for subj in ca_subj_data_paths:\n",
    "    subj_cat_df = pd.read_csv(subj)\n",
    "    if subj_cat_df.iloc[0,0] != 0:\n",
    "        if meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == subj.split('_')[num]].index.empty:\n",
    "            continue\n",
    "        else:  # If match is found, this runs\n",
    "            soc_id = meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == subj.split('_')[num]].index[0]\n",
    "            soc_id = soc_id.replace('soc','sub')\n",
    "            meadows_id = subj.split('_')[num]\n",
    "\n",
    "        subj_no_list.append(soc_id)\n",
    "        meadows_id_no_list.append(meadows_id)\n",
    "        \n",
    "print(len(subj_no_list))\n",
    "subj_no_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577173c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:33:12.243748Z",
     "start_time": "2022-12-15T13:33:12.225829Z"
    }
   },
   "source": [
    "There were also two versions of relationships, like what happened in Multi-Arrangement Task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d57fcfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:57.023860Z",
     "start_time": "2022-12-15T13:37:56.470536Z"
    }
   },
   "outputs": [],
   "source": [
    "subject_cat_relationships_frames = {}\n",
    "\n",
    "for subj in ca_subj_data_paths:\n",
    "    \n",
    "    if meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == subj.split('_')[num]].index.empty:\n",
    "        continue\n",
    "    else:  # If match is found, this runs\n",
    "        soc_id = meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == subj.split('_')[num]].index[0]\n",
    "        soc_id = soc_id.replace('soc','sub')\n",
    "        \n",
    "    ############\n",
    "    #Separate the two conditons where some had index of numbers while others not.\n",
    "    if soc_id in subj_no_list:\n",
    "        subj_cat_df = pd.read_csv(subj)\n",
    "    else:\n",
    "        subj_cat_df = pd.read_csv(subj).iloc[:, 1:]\n",
    "    ############ \n",
    "    \n",
    "    # abstract relationships from each matrix, for checking whether relationships were the same or different?\n",
    "    relationships = []\n",
    "    for col in subj_cat_df.columns:\n",
    "        for i in list(subj_cat_df.index):\n",
    "            temp_rel = subj_cat_df.loc[i,col]\n",
    "            relationships.append(temp_rel)\n",
    "    relationships = [x for x in relationships if pd.isnull(x) == False]\n",
    "    relationships = list(set(relationships))\n",
    "    \n",
    "    subject_cat_relationships_frames[soc_id] = relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1722bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:57.038870Z",
     "start_time": "2022-12-15T13:37:57.024860Z"
    }
   },
   "outputs": [],
   "source": [
    "relationship_ca_v1 = subject_cat_relationships_frames[list(subject_cat_relationships_frames.keys())[0]]\n",
    "relationship_ca_v2 = subject_cat_relationships_frames[list(subject_cat_relationships_frames.keys())[59]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f5f8ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:37:57.053875Z",
     "start_time": "2022-12-15T13:37:57.040873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sub-762', 'sub-763', 'sub-765', 'sub-766', 'sub-502', 'sub-764', 'sub-767']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_rel_v2 = []\n",
    "for i in list(subject_cat_relationships_frames.keys()):\n",
    "    if any(set(relationship_ca_v1) - set(subject_cat_relationships_frames[i])):\n",
    "        subj_rel_v2.append(i)\n",
    "        #print(len(subject_cat_relationships_frames[i]),end='')\n",
    "        #print(i,end='')\n",
    "        #print(set(subject_cat_relationships_frames[i]) - set(relationship_ca_v1))\n",
    "subj_rel_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64253963",
   "metadata": {},
   "source": [
    "## Main transfer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b6d74b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-15T13:57:13.803201Z",
     "start_time": "2022-12-15T13:38:53.068922Z"
    }
   },
   "outputs": [],
   "source": [
    "subject_cat_frames = {}\n",
    "\n",
    "for subj in ca_subj_data_paths:\n",
    "    \n",
    "    if meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == subj.split('_')[num]].index.empty:\n",
    "        continue\n",
    "    else:  # If match is found, this runs\n",
    "        soc_id = meadows_soc_id_key[meadows_soc_id_key['meadows_id'] == subj.split('_')[num]].index[0]\n",
    "        soc_id = soc_id.replace('soc','sub')\n",
    "        \n",
    "    ############ different format of dataframe\n",
    "    #Separate the two conditons where some had index of numbers while others not.\n",
    "    if soc_id in subj_no_list:\n",
    "        subj_cat_df = pd.read_csv(subj)\n",
    "    else:\n",
    "        subj_cat_df = pd.read_csv(subj).iloc[:, 1:]\n",
    "    ############ \n",
    "    \n",
    "    ############ different relationship labels\n",
    "    #There were two versions of relationships.\n",
    "    if soc_id in subj_rel_v2:\n",
    "        relationships = relationship_ca_v2\n",
    "    else:\n",
    "        relationships = relationship_ca_v1\n",
    "    ############ \n",
    "    \n",
    "    rdm_cat = pd.DataFrame(columns=relationships)\n",
    "    for rel_a in relationships:\n",
    "        temp_relv_cols = []\n",
    "        [temp_relv_cols.append(col) for col in subj_cat_df.columns if rel_a in subj_cat_df[col].tolist()]\n",
    "\n",
    "        for rel_b in relationships:\n",
    "            temp_relv_cols_b = []\n",
    "            [temp_relv_cols_b.append(col) for col in subj_cat_df.columns if rel_b in subj_cat_df[col].tolist()]\n",
    "\n",
    "            if subj_cat_df[temp_relv_cols].isin([rel_b]).any().any():\n",
    "                rdm_cat.loc[rel_a,rel_b] = 0          \n",
    "                # set strict criterion\n",
    "                if (len(temp_relv_cols) > 1)|(len(temp_relv_cols_b) > 1):               \n",
    "                    if temp_relv_cols != temp_relv_cols_b:\n",
    "                        rdm_cat.loc[rel_a,rel_b] = 1\n",
    "            else:\n",
    "                rdm_cat.loc[rel_a,rel_b] = 1\n",
    "            \n",
    "    ### Turn relationships labels in version 2 into version 1.\n",
    "    if soc_id in subj_rel_v2:\n",
    "        rdm_cat = rel_v2_to_v1(rdm_cat)\n",
    "        rdm_cat = rdm_cat.loc[relationship_ca_v1,relationship_ca_v1]\n",
    "    ###\n",
    "            \n",
    "    #rdm_cat = rdm_cat.fillna(0) I think this step was not necessary. \n",
    "    \n",
    "    ############\n",
    "    #Add the labels' adjustment\n",
    "    rdm_cat = fix_df_labels(rdm_cat)\n",
    "    ############\n",
    "    subject_cat_frames[soc_id] = rdm_cat\n",
    "    \n",
    "    rdm_cat.to_csv('../output_data/individual/category/Subject_Category_RDMs_revised/'+ soc_id + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
